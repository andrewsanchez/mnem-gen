{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a list of consonants and combinations of consonants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import string, re, itertools\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import Counter\n",
    "from nltk.corpus import wordnet as wn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "alphabet_lowercase = list(string.ascii_lowercase)\n",
    "vowels = [\"a\",\"e\",\"i\",\"o\",\"u\",\"y\"]\n",
    "consonants = [letter for letter in alphabet_lowercase if letter not in vowels ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "two_consonant_reduced_words: 326\n",
      "three_consonant_reduced_words: 2201\n",
      "double_combos: 210\n",
      "triple_combos: 1540\n",
      "double_perms: 380\n",
      "triple_perms: 6840\n",
      "pairs_all: 400\n",
      "triplets_all: 7240\n"
     ]
    }
   ],
   "source": [
    "two_consonant_reduced_words = []\n",
    "three_consonant_reduced_words = []\n",
    "for synset in list(wn.all_synsets('n')):\n",
    "    word = synset.name().split(\".\")[0].lower()\n",
    "    if \"_\" not in word:\n",
    "        reduced_word = re.sub(\"[aeiouy\\W]\", \"\", word)\n",
    "        reduced_word = re.sub(r'([a-z])\\1+', r'\\1', reduced_word)\n",
    "        if len(reduced_word) == 2 and reduced_word not in two_consonant_reduced_words:\n",
    "            two_consonant_reduced_words.append(reduced_word)\n",
    "        if len(reduced_word) == 3 and reduced_word not in three_consonant_reduced_words:\n",
    "            three_consonant_reduced_words.append(reduced_word)\n",
    "\n",
    "double_combos = itertools.combinations_with_replacement(consonants, 2)\n",
    "double_combos = [pair[0]+pair[1] for pair in double_combos]\n",
    "triple_combos = itertools.combinations_with_replacement(consonants, 3)\n",
    "triple_combos = [pair[0]+pair[1]+pair[2] for pair in triple_combos]\n",
    "\n",
    "double_perms = itertools.permutations(consonants, 2)\n",
    "double_perms = [pair[0]+pair[1] for pair in double_perms]\n",
    "triple_perms = itertools.permutations(consonants, 3)\n",
    "triple_perms = [pair[0]+pair[1]+pair[2] for pair in triple_perms]\n",
    "\n",
    "pairs_all = []\n",
    "triplets_all = []\n",
    "for pair in double_combos:\n",
    "    if pair not in pairs_all:\n",
    "        pairs_all.append(pair)\n",
    "for pair in double_perms:\n",
    "    if pair not in pairs_all:\n",
    "        pairs_all.append(pair)\n",
    "for pair in triple_combos:\n",
    "    if pair not in triplets_all:\n",
    "        triplets_all.append(pair)\n",
    "for pair in triple_perms:\n",
    "    if pair not in triplets_all:\n",
    "        triplets_all.append(pair)\n",
    "        \n",
    "print(\"two_consonant_reduced_words: {}\".format(len(two_consonant_reduced_words)))\n",
    "print(\"three_consonant_reduced_words: {}\".format(len(three_consonant_reduced_words)))\n",
    "print(\"double_combos: {}\".format(len(double_combos)))\n",
    "print(\"triple_combos: {}\".format(len(triple_combos)))\n",
    "print(\"double_perms: {}\".format(len(double_perms)))\n",
    "print(\"triple_perms: {}\".format(len(triple_perms)))\n",
    "print(\"pairs_all: {}\".format(len(pairs_all)))\n",
    "print(\"triplets_all: {}\".format(len(triplets_all)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Filter pairs from this list that produce low frequency matches according to the regex:\n",
    "\n",
    "`[aeiouyh]*[pair]+[aeiouyh]*`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "re.compile('[aeiouhy]*[df]+[aeiouhy]*')\n",
      "re.compile('[aeiouhy]*[dg]+[aeiouhy]*')\n",
      "re.compile('[aeiouhy]*[dj]+[aeiouhy]*')\n",
      "re.compile('[aeiouhy]*[dk]+[aeiouhy]*')\n",
      "re.compile('[aeiouhy]*[dl]+[aeiouhy]*')\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-c0b7aa552e97>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0msynset\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mall_synsets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'n'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m         \u001b[0mword\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msynset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\".\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/andrew/anaconda3/lib/python3.5/site-packages/nltk/corpus/reader/wordnet.py\u001b[0m in \u001b[0;36mall_synsets\u001b[0;34m(self, pos)\u001b[0m\n\u001b[1;32m   1530\u001b[0m                         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1531\u001b[0m                             \u001b[0;32myield\u001b[0m \u001b[0msynset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1532\u001b[0;31m                     \u001b[0moffset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata_file\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtell\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1533\u001b[0m                     \u001b[0mline\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata_file\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1534\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/andrew/anaconda3/lib/python3.5/site-packages/nltk/data.py\u001b[0m in \u001b[0;36mtell\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1324\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstream\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseek\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_rewind_checkpoint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1325\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_char_seek_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_rewind_numchars\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mest_bytes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1326\u001b[0;31m         \u001b[0mfilepos\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstream\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtell\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1327\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1328\u001b[0m         \u001b[0;31m# Sanity check\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "columns=[\"matches\"]\n",
    "df = pd.DataFrame(index=combos_14, columns=columns)\n",
    "\n",
    "for i in combos_14:\n",
    "    re_list = [\"[aeiouhy]*\"]\n",
    "    matches = []\n",
    "    \n",
    "    p = \"[\"+i+\"]\"+\"+\"\n",
    "    re_list.append(p)\n",
    "    re_list.append(\"[aeiouhy]*\")\n",
    "    p = re.compile(\"\".join(re_list))\n",
    "    print(p)\n",
    "    \n",
    "    for synset in list(wn.all_synsets('n')):\n",
    "        word = synset.name().split(\".\")[0]\n",
    "        if p.match(word):\n",
    "            matches.append(word)\n",
    "            \n",
    "    df.loc[i,[\"matches\"]] = len(matches)\n",
    "\n",
    "df.to_csv(\"match_freqs_all.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "matches_data = \"match_freqs_10\"\n",
    "df = pd.read_csv(matches_data+\".csv\", index_col=0)\n",
    "df = df.sort_values(\"matches\", ascending=False)\n",
    "# df.plot(kind=\"bar\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "group = []\n",
    "for i in df.index:\n",
    "    if i[0] not in \"\".join(group) and i[1] not in \"\".join(group):\n",
    "        group.append(i)\n",
    "\n",
    "print(group)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "num_char_dic = {0: \"sz\",\n",
    "                1: \"td\",\n",
    "                2: \"nm\",\n",
    "                3: \"ck\",\n",
    "                4: \"rl\",\n",
    "                5: \"fv\",\n",
    "                6: \"hj\",\n",
    "                7: \"gq\",\n",
    "                8: \"wx\",\n",
    "                9: \"pb\"}\n",
    "\n",
    "replacements = ((\"sz\", \"0\"),\n",
    "                (\"td\", \"1\"),\n",
    "                (\"nm\", \"2\"),\n",
    "                (\"ck\", \"3\"),\n",
    "                (\"rl\", \"4\"),\n",
    "                (\"fv\", \"5\"),\n",
    "                (\"hj\", \"6\"),\n",
    "                (\"gq\", \"7\"),\n",
    "                (\"wx\", \"8\"),\n",
    "                (\"pb\", \"9\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'stein'"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word = \"ssteinn\"\n",
    "\n",
    "\n",
    "\n",
    "word\n",
    "\n",
    "# for letter in word:\n",
    "#     if word[word.index(letter)+1] == letter:\n",
    "#         del letter\n",
    "# print(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'s'"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word = iter(word)\n",
    "next(word)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove vowels and consecutive duplicate letters\n",
    "\n",
    "Convert word to number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "stn\n",
      "012\n"
     ]
    }
   ],
   "source": [
    "word = \"steinn\"\n",
    "word = word.lower()\n",
    "word = re.sub(\"[aeiou\\W]\", \"\", word)\n",
    "word = re.sub(r'([a-z])\\1+', r'\\1', word)\n",
    "print(word)\n",
    "\n",
    "number = []\n",
    "for letter in word:\n",
    "    for lset, num in replacements:\n",
    "        if letter in lset:\n",
    "            number.append(num)\n",
    "\n",
    "print(\"\".join(number))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-66-cd9d0a205bea>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m10000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0msynset\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mall_synsets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'n'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0mword\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msynset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\".\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/andrew/anaconda3/lib/python3.5/site-packages/nltk/corpus/reader/wordnet.py\u001b[0m in \u001b[0;36mall_synsets\u001b[0;34m(self, pos)\u001b[0m\n\u001b[1;32m   1517\u001b[0m                         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1518\u001b[0m                             \u001b[0;31m# Otherwise, parse the line\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1519\u001b[0;31m                             \u001b[0msynset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfrom_pos_and_line\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpos_tag\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mline\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1520\u001b[0m                             \u001b[0mcache\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpos_tag\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0moffset\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msynset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1521\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/andrew/anaconda3/lib/python3.5/site-packages/nltk/corpus/reader/wordnet.py\u001b[0m in \u001b[0;36m_synset_from_pos_and_line\u001b[0;34m(self, pos, data_file_line)\u001b[0m\n\u001b[1;32m   1324\u001b[0m                 \u001b[0mlex_id\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_next_token\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m16\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1325\u001b[0m                 \u001b[0;31m# If the lemma has a syntactic marker, extract it.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1326\u001b[0;31m                 \u001b[0mm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mre\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mr'(.*?)(\\(.*\\))?$'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlemma_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1327\u001b[0m                 \u001b[0mlemma_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msyn_mark\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroups\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1328\u001b[0m                 \u001b[0;31m# create the lemma object\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/andrew/anaconda3/lib/python3.5/re.py\u001b[0m in \u001b[0;36mmatch\u001b[0;34m(pattern, string, flags)\u001b[0m\n\u001b[1;32m    161\u001b[0m     \"\"\"Try to apply the pattern at the start of the string, returning\n\u001b[1;32m    162\u001b[0m     a match object, or None if no match was found.\"\"\"\n\u001b[0;32m--> 163\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_compile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpattern\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstring\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    164\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mfullmatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpattern\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstring\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "columns=[\"matches\"]\n",
    "nums_from_words = []\n",
    "df = pd.DataFrame(index=range(0,10000), columns=columns)\n",
    "\n",
    "for synset in list(wn.all_synsets('n')):\n",
    "    word = synset.name().split(\".\")[0]\n",
    "    word = word.lower()\n",
    "    word = re.sub(\"[aeiou\\W]\", \"\", word)\n",
    "    word = re.sub(r'([a-z])\\1+', r'\\1', word)\n",
    "    \n",
    "    number = []\n",
    "    for letter in word:\n",
    "        for lset, num in replacements:\n",
    "            if letter in lset:\n",
    "                number.append(num)\n",
    "    \n",
    "    if len(number) < 5:\n",
    "        nums_from_words.append(\"\".join(number))\n",
    "        \n",
    "print(len(nums_from_words))\n",
    "nums_from_words = Counter(nums_from_words)\n",
    "print(nums_from_words)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
